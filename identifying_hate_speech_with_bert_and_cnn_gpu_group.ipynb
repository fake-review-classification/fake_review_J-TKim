{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "baS0lOejtaxT"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transformers\n",
    "\n",
    "from preprocessing import preprocessing\n",
    "from tokenize_and_pad_text import *\n",
    "from train_model import KimCNN, train_test_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version\n",
      "python version==3.6.5\n",
      "pandas==1.1.5\n",
      "numpy==1.19.2\n",
      "torch==1.7.1\n",
      "sklearn==0.24.1\n",
      "transformers==3.5.0\n",
      "matplotlib==3.3.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('version')\n",
    "print(f\"python version=={python_version()}\")\n",
    "print(f\"pandas=={pd.__version__}\")\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"torch=={torch.__version__}\")\n",
    "print(f\"sklearn=={sklearn.__version__}\")\n",
    "print(f\"transformers=={transformers.__version__}\")\n",
    "print(f\"matplotlib=={matplotlib.__version__}\",end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = transformers.BertModel\n",
    "tokenizer_class = transformers.BertTokenizer\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "target_columns = ['label']\n",
    "\n",
    "max_seq = 128\n",
    "bert_batch_size = 16\n",
    "\n",
    "kernel_num = 3\n",
    "kernel_sizes = [2, 3, 4]\n",
    "dropout = 0.5\n",
    "static = True\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 64\n",
    "lr = 0.005\n",
    "optimizer = torch.optim.Adam\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: Quadro RTX 6000\n",
      "use reviews.csv data\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "\n",
    "    print(f'We will use the GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "data_path = '../reviews.csv'\n",
    "data_name = data_path.split('/')[-1]\n",
    "print(f'use {data_name} data', end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(threshold):\n",
    "    if threshold == 1:\n",
    "        print('test with add word!!!')\n",
    "    else:\n",
    "        print(f'start threshold {threshold}!!!')\n",
    "    preprocessing_class = preprocessing(df, threshold=threshold)\n",
    "\n",
    "    df_train, df_val, df_test = preprocessing_class.preprocessing_all()\n",
    "\n",
    "    print('make train data ...')\n",
    "    x_train, y_train = tokenize_and_pad_text_bert(df_train, device, model_class, tokenizer_class, pretrained_weights,\n",
    "                                                max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n",
    "\n",
    "    print('make valid data ...')\n",
    "    x_val, y_val = tokenize_and_pad_text_bert(df_val, device, model_class, tokenizer_class, pretrained_weights,\n",
    "                                                max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n",
    "\n",
    "    print('make test data ...')\n",
    "    x_test, y_test = tokenize_and_pad_text_bert(df_test, device, model_class, tokenizer_class, pretrained_weights,\n",
    "                                                max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n",
    "\n",
    "    embed_num = x_train.shape[1]\n",
    "    embed_dim = x_train.shape[2]\n",
    "    class_num = y_train.shape[1]\n",
    "\n",
    "    model = KimCNN(\n",
    "        embed_num=embed_num,\n",
    "        embed_dim=embed_dim,\n",
    "        class_num=class_num,\n",
    "        kernel_num=kernel_num,\n",
    "        kernel_sizes=kernel_sizes,\n",
    "        dropout=dropout,\n",
    "        static=static,\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # train and test\n",
    "    review_classification_model = train_test_model(model)\n",
    "    review_classification_model.train(x_train, y_train, x_val, y_val)\n",
    "    y_test_np, y_preds_np = review_classification_model.test(x_test, y_test)\n",
    "    \n",
    "    auc_scores = roc_auc_score(y_test_np, y_preds_np, average=None)\n",
    "\n",
    "    print(f'threshold : {threshold},\\tauc ascores : {auc_scores}')\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|1|0.9|0.8|0.7|0.6|0.5|0.4|0.3|0.2|0.1|\n",
    "|------|---|---|------|---|---|------|---|---|------|\n",
    "|0.675862875|0.66581|0.668417|acc1|acc1|acc1|acc1|acc1|acc1|acc1|\n",
    "|0.6803092499999999|0.670507625|0.6678055|0.661810625|0.653615375|0.6213356250000001|acc1|acc1|acc1|acc1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test with add word!!!\n",
      "make id dictionary and count id frequency of id ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358957/358957 [00:07<00:00, 49326.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label is changed!!! (-1, 1) => (0, 1)\n",
      "\n",
      "length of real review : 322097, length of fake review : 36860\n",
      "\n",
      "train val test split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 596/20000 [00:00<00:03, 5950.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(del_word_lst): 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:03<00:00, 5903.10it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6041.10it/s]\n",
      "100%|██████████| 4000/4000 [00:00<00:00, 5988.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make train data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 450/1249 [00:28<01:17, 10.33it/s]"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "\n",
    "main(threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_path)\n",
    "\n",
    "# main(threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_path)\n",
    "\n",
    "# main(threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_path)\n",
    "\n",
    "# main(threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_path)\n",
    "\n",
    "# main(threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "\n",
    "main(threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "\n",
    "main(threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "\n",
    "main(threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "\n",
    "main(threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "\n",
    "main(threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "identifying-hate-speech-with-bert-and-cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "JT",
   "language": "python",
   "name": "jt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
