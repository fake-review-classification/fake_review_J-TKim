{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "baS0lOejtaxT"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vJPwpokJtaxZ"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transformers\n",
    "\n",
    "\n",
    "from preprocessing import preprocessing\n",
    "from tokenize_and_pad_text import *\n",
    "from train_model import KimCNN, train_test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gN48AzdNEUnX"
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = transformers.BertModel\n",
    "tokenizer_class = transformers.BertTokenizer\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "target_columns = ['label']\n",
    "\n",
    "max_seq = 128\n",
    "bert_batch_size = 16\n",
    "\n",
    "kernel_num = 3\n",
    "kernel_sizes = [2, 3, 4]\n",
    "dropout = 0.5\n",
    "static = True\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(threshold):\n",
    "    print(f'start threshold {threshold}!!!')\n",
    "    preprocessing_class = preprocessing(df)\n",
    "\n",
    "    df_train, df_val, df_test = preprocessing_class.preprocessing_all()\n",
    "\n",
    "    print('make train data ...')\n",
    "    x_train, y_train = tokenize_and_pad_text_bert(df_train, device, model_class, tokenizer_class, pretrained_weights,\n",
    "                                                max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n",
    "\n",
    "    print('make valid data ...')\n",
    "    x_val, y_val = tokenize_and_pad_text_bert(df_val, device, model_class, tokenizer_class, pretrained_weights,\n",
    "                                                max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n",
    "\n",
    "    print('make train data ...')\n",
    "    x_test, y_test = tokenize_and_pad_text_bert(df_test, device, model_class, tokenizer_class, pretrained_weights,\n",
    "                                                max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n",
    "\n",
    "    embed_num = x_train.shape[1]\n",
    "    embed_dim = x_train.shape[2]\n",
    "    class_num = y_train.shape[1]\n",
    "\n",
    "    model = KimCNN(\n",
    "        embed_num=embed_num,\n",
    "        embed_dim=embed_dim,\n",
    "        class_num=class_num,\n",
    "        kernel_num=kernel_num,\n",
    "        kernel_sizes=kernel_sizes,\n",
    "        dropout=dropout,\n",
    "        static=static,\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # train and test\n",
    "    review_classification_model = train_test_model(model)\n",
    "    review_classification_model.train(x_train, y_train, x_val, y_val)\n",
    "    auc_scores = review_classification_model.test(x_test, y_test)\n",
    "\n",
    "    print(f'threshold : {threshold},\\tauc ascores : {auc_scores}')\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version\n",
      "python version==3.7.5\n",
      "pandas==1.2.0\n",
      "numpy==1.19.4\n",
      "torch==1.7.1+cu101\n",
      "sklearn==0.24.0\n",
      "transformers==3.5.0\n",
      "matplotlib==3.3.3\n",
      "\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-DGXS-32GB\n",
      "\n",
      "use reviews.csv data\n",
      "make id dictionary and count id frequency of id ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358957/358957 [00:06<00:00, 52866.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label is changed!!! (-1, 1) => (0, 1)\n",
      "\n",
      "length of real review : 322097, length of fake review : 36860\n",
      "\n",
      "train val test split\n",
      "make train data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 655/1249 [01:03<00:57, 10.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-377ccc558f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-049c54ecabfb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(threshold)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'make train data ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     x_train, y_train = tokenize_and_pad_text_bert(df_train, device, model_class, tokenizer_class, pretrained_weights,\n\u001b[0;32m----> 8\u001b[0;31m                                                 max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'make valid data ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fake_review_classification/tokenize_and_pad_text.py\u001b[0m in \u001b[0;36mtokenize_and_pad_text_bert\u001b[0;34m(df, device, model_class, tokenizer_class, pretrained_weights, max_seq, batch_size, target_columns)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('version')\n",
    "print(f\"python version=={python_version()}\")\n",
    "print(f\"pandas=={pd.__version__}\")\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"torch=={torch.__version__}\")\n",
    "print(f\"sklearn=={sklearn.__version__}\")\n",
    "print(f\"transformers=={transformers.__version__}\")\n",
    "print(f\"matplotlib=={matplotlib.__version__}\",end='\\n\\n')\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "\n",
    "    print(f'We will use the GPU: {torch.cuda.get_device_name(0)}', end='\\n\\n')\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\", end='\\n\\n')\n",
    "    \n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "data_path = '../reviews.csv'\n",
    "data_name = data_path.split('/')[-1]\n",
    "print(f'use {data_name} data', end='\\n')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "for threshold10 in range(1, 10):\n",
    "    threshold = threshold10 / 10\n",
    "    main(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "identifying-hate-speech-with-bert-and-cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
