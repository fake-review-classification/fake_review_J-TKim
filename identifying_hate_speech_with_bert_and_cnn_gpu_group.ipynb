{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "baS0lOejtaxT"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from platform import python_version\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transformers\n",
    "\n",
    "from preprocessing import preprocessing\n",
    "from tokenize_and_pad_text import *\n",
    "from train_model import KimCNN, train_test_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version\n",
      "python version==3.7.5\n",
      "pandas==1.2.0\n",
      "numpy==1.19.4\n",
      "torch==1.7.1+cu101\n",
      "sklearn==0.24.0\n",
      "transformers==3.5.0\n",
      "matplotlib==3.3.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('version')\n",
    "print(f\"python version=={python_version()}\")\n",
    "print(f\"pandas=={pd.__version__}\")\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"torch=={torch.__version__}\")\n",
    "print(f\"sklearn=={sklearn.__version__}\")\n",
    "print(f\"transformers=={transformers.__version__}\")\n",
    "print(f\"matplotlib=={matplotlib.__version__}\",end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = transformers.BertModel\n",
    "tokenizer_class = transformers.BertTokenizer\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "target_columns = ['label']\n",
    "\n",
    "max_seq = 128\n",
    "bert_batch_size = 16\n",
    "\n",
    "kernel_num = 3\n",
    "kernel_sizes = [2, 3, 4]\n",
    "dropout = 0.5\n",
    "static = True\n",
    "\n",
    "n_epochs = 50\n",
    "patience = 5\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "k_fold = 5\n",
    "optimizer = torch.optim.Adam\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-DGXS-32GB\n",
      "use reviews.csv data\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "\n",
    "    print(f'We will use the GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "data_path = '../reviews.csv'\n",
    "data_name = data_path.split('/')[-1]\n",
    "print(f'use {data_name} data', end='\\n')\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ratio_threshold, preprocessing_function=(None, None), dist_type=None, dist_threshold=1, random_seed=42):\n",
    "    \n",
    "    if preprocessing_function[0] != 'check_around_words':\n",
    "        assert 0 <= ratio_threshold <= 1, 'ratio threshold must between 0 and 1'\n",
    "        print(f'start threshold {ratio_threshold}!!!')\n",
    "    \n",
    "    preprocessing_class = preprocessing(df,random_seed=random_seed)\n",
    "\n",
    "    df_train, df_val, df_test = preprocessing_class.preprocessing_all(ratio_threshold=ratio_threshold, preprocessing_function=preprocessing_function, dist_type=dist_type, dist_threshold=1)\n",
    "    \n",
    "    print('make train data ...')\n",
    "    x_train, y_train = tokenize_and_pad_text_bert(df_train, device, model_class, tokenizer_class, pretrained_weights,\n",
    "                                                max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n",
    "\n",
    "    print('make valid data ...')\n",
    "    x_val, y_val = tokenize_and_pad_text_bert(df_val, device, model_class, tokenizer_class, pretrained_weights,\n",
    "                                                max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n",
    "\n",
    "    print('make test data ...')\n",
    "    x_test, y_test = tokenize_and_pad_text_bert(df_test, device, model_class, tokenizer_class, pretrained_weights,\n",
    "                                                max_seq=max_seq, batch_size=bert_batch_size, target_columns=target_columns)\n",
    "\n",
    "    embed_num = x_train.shape[1]\n",
    "    embed_dim = x_train.shape[2]\n",
    "    class_num = y_train.shape[1]\n",
    "\n",
    "    auc_score_list = []\n",
    "    \n",
    "    for fold in range(k_fold):\n",
    "        model = KimCNN(\n",
    "            embed_num=embed_num,\n",
    "            embed_dim=embed_dim,\n",
    "            class_num=class_num,\n",
    "            kernel_num=kernel_num,\n",
    "            kernel_sizes=kernel_sizes,\n",
    "            dropout=dropout,\n",
    "            static=static,\n",
    "        )\n",
    "\n",
    "        model = model.to(device)\n",
    "\n",
    "        # train and test\n",
    "        review_classification_model = train_test_model(model, n_epochs, batch_size, lr, optimizer, loss_fn)\n",
    "        # auc_score_list = review_classification_model.kfold_train_test(x_train, y_train, x_test, y_test, kwargs, k_fold=5)\n",
    "\n",
    "        review_classification_model.train(x_train, y_train, x_val, y_val, fold=0, patience=patience)\n",
    "        y_test_np, y_preds_np = review_classification_model.test(x_test, y_test)\n",
    "\n",
    "        auc_score = roc_auc_score(y_test_np, y_preds_np, average=None)\n",
    "        print(f'k_fold: {fold+1}/{k_fold},\\tauc score: {auc_score}')\n",
    "        auc_score_list.append(auc_score)\n",
    "        \n",
    "    print(f'ratio_threshold: {ratio_threshold},\\tauc score: {np.mean(auc_score_list)}, std: {np.std(auc_score_list)}')\n",
    "    return auc_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_threshold = 1\n",
    "preprocessing_function = (None, None) # (None, None), ('dist_del_words', None), ('check_around_words', True), ('check_around_word', False)\n",
    "dist_type = 'cosine_similarity' # input cosine_similarity, eucliean_distance or None if you don't want to delite word considering the distance\n",
    "dist_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start threshold 1!!!\n",
      "make id dictionary and count id frequency of id ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358957/358957 [00:06<00:00, 53722.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label is changed!!! (-1, 1) => (0, 1)\n",
      "\n",
      "length of real review : 322097, length of fake review : 36860\n",
      "\n",
      "train val test split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 762/20000 [00:00<00:02, 7617.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save\n",
      "done\n",
      "len(del_word_list): 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:02<00:00, 7627.65it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7823.93it/s]\n",
      "100%|██████████| 4000/4000 [00:00<00:00, 7761.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make train data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 763/1249 [01:21<01:13,  6.59it/s]"
     ]
    }
   ],
   "source": [
    "main(ratio_threshold, preprocessing_function, dist_type, dist_threshold)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "identifying-hate-speech-with-bert-and-cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
